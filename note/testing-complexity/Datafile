@title
Testing O(n!) Complexity / 複雑系に立ち向かう

@header
Testing O(n!) Complexity / 複雑系に立ち向かう

@nav
..
.

@chapter
序文

　なにかをつくるという行為において、テストは常に課題としてつきまといます。ソフトウェアにおいては、
たとえば機能 A, B, C, … を開発したとして、そのテストを t(A), t(B), t(C), … と書くことにします。

　　機能: A, B, C, …

　　テスト: t(A), t(B), t(C), …

　さてそれぞれの機能について、 A を使ったあとに B を使う、あるいは A と B を別人が同時に使うなどした
場合にのみ発生するバグというものがあります。これは当然 t(A), t(B) だけではテストできませんから、
このように A, B の組み合わせでのみ起こる種類のバグをテストするものを t(A, B) などと書くことにします。
順序を考慮する (つまりたいていの) 場合、テストは A, B, C, … の置換の数だけ必要になります。

　　機能: A, B, C, …

　　テスト: …, t(A, B, C), t(A, C, B), t(B, A, C), t(B, C, A), t(C, A, B), t(C, B, A), …

　結局、機能 n 個に対して、必要なテストの数は n! 個や 1! + 2! + … + n! 個 にもなってしまいます。
つまりテスト項目は O(n!) で増加します (※オーダーを考えるときは『増加量』に着目するので O(1! + 2! + … + n!) とはしません。
このことから上記のいずれの場合もひっくるめて O(n!) でテスト項目が増える、と表現します) 。

　もし、テストを書かなければ O(n) で開発ができるかもしれません。それは O(n!) のコストを支払っていないので、
当然すばやく開発できますがどこかで綻びが生まれます。もちろん n! 個の (自動) テストを人間が書くなど無理な話です。

　テストをしつつ、開発も O(n) で進めるなど可能なのでしょうか？

@chapter
『組み合わせても安全』な性質を考える

　さて機能 A, B について、そのテスト t(A), t(B) は書けたとしましょう。
オーダーが O(n!) になりますから、 t(A, B), t(B, A) を手動で書くことは困難です。
ここでとれる手段は大別すればふたつ

　　　　t(A, B), t(B, A) を自動生成する

　　　　もし t(A) と t(B) が pass するならば t(A, B) と t(B, A) も pass するという性質を満たすように A, B を実装する

　となります。

@chapter
∀ の重要な性質に着目する

　ここで型の言葉で『組み合わせても安全』な性質というものを考えてみます。
これは実際には型でそうする必要はありません (proptest とかでもいいと思います) が、概念として考えてみます。

　　　　f : ∀a &lt;: T. a → U

　　　　S &lt;: T

　　　　x : S

　　　　f(x) : U

　さて t(f), t(x) が書けたとします。また y : U に関する t(y) を所与のものとします。
ここで t(f, x) := t(f(x)) や t(x, f) := t(f(x)) とします。
これは

　　　　t(A, B), t(B, A) を自動生成する

　　　　もし t(f), t(x) が pass するならば t(f, x) と t(x, f) も正しい

　という性質を (うまく実装すれば) 満たします。

　ここで (うまく実装すれば) という部分は人間の手腕にも依りますが、基本的には ∀ の性質を満たすように
テストを書くということです。つまり

　　　　t(f) …… すべての a &lt;: T, x : a について、 x が意味的に正しいならば f(x) も意味的に正しい

　　　　t(x) …… x は意味的に正しい

　　　　t(y) …… y は意味的に正しい

　上記の『意味的に正しい』という言葉を厳密に定義することはありませんが、基本的には
型のうえでのエラーではなく、意味論的なエラーがないことを保証するものです。
たとえば f(n, m) := n + m と g(n, m) := n - m は型のうえではエラーにはなりませんが、
意味的には異なります。また t(y) に関してはプログラムで判定せずとも、人間が出力を目で見るといった方法もあります。

　上記のような関係が定義できる具体的な機能は、 Rust の trait や Haskell の型クラスなどがあります。

　　　　Rust の場合 ∀a &lt;: T. の部分を trait 境界で読み替える

　　　　Haskell の場合 ∀a &lt;: T. の部分を型クラス制約で読み替える

　とすればよいのです。

@chapter
実は単相でもいい

　上記とまったく同じ議論が単相な型においてもできることは、すぐに気づかれるかもしれません。
というのは

　　　　f : T → U

　　　　x : T

　　　　f(x) : U

　のようにしても、実際のところまったく同じことが言えるからです。つまり

　　　　t(f) …… すべての x : T について、 x が意味的に正しいならば f(x) も意味的に正しい

　　　　t(x) …… x は意味的に正しい

　としても、実際あまり変わりはありません。
これは言語機能での抽象化が難しい場合には重要な考え方です。

@chapter
グラフの辺や頂点に着目する / 単位 (unit) と単位テスト (unit test)

　識別子を頂点、その組み合わせを辺として、ソースコードをグラフ状に見ることができます。

　　　　{f, x} ⊆ V

　　　　{f(x)} ⊆ E

　ということです (V は頂点、 E は辺の集合) 。

　さてこれはグラフに関する一般的な事実ですが |V| = n とするならば |E| は最大 n×(n-1) 個存在します (完全グラフ)。
一方で辺がほとんど存在しないものもあります (疎グラフ)。
辺がたくさん存在するものを密グラフとか言います。

　ここで重要なのは人間が実装するものに関する考え方です。通常実装するものは頂点、つまり f, x といったものです。
一方でその組み合わせたる辺、つまり f(x) は膨大な数に及び、これを人間が (unit に分解せずに) 書くことは不可能に近いでしょう。
さらに g(f(x)) のようにみっつの頂点を含む道について考え始めると手に負えなくなってきます。

　これは最終的に実装したい機能が f(x) だとしても、これをより f, x といった単位 (unit) に分解していくことで、
最小の実装項目で最大の機能を開発できるという考え方です。

　またここで単位 (unit) という言葉を出したのは、これが unit test に関する重要な考え方だからです。

@chapter
『組み合わせることができる』ものを考える

　さて『組み合わせても安全』なものは、ひとつで複数の機能を表すことができます。
たとえば

　　　　f : ∀a &lt;: T. a → U

　　　　S1 &lt;: T, S2 &lt;: T, …, Sn &lt;: T

　　　　x1 : S1, x2 : S2, …, xn : Sn

　とします。これは

　　　　f(x1) : U, f(x2) : U, …, f(xn) : U

　のように、たったひとつの関数と n 個の値によって n 個の機能を実装できたことになります。
さらにテストも t(f), t(x1), t(x2), …, t(xn) を書くことによって、上記の『組み合わせても安全』な性質により
機能それぞれの品質も保証されています。ここで t(f), t(x1), t(x2), …, t(xn) は unit test ということになります。

　また f も増やすことができます。つまり f1, f2, …, fm と増やすと、それぞれの x1, x2, …, xn の
組み合わせだけ機能を実装することができます。

@chapter
Expression Problem に関する考え方 / なにが問題でなにを解決する？

　Expression Problem というものがあります。
これ自体は古くからある問題で、とくに新しいものではありません。

　たびたび『型クラスは Expression Problem を解決できる』というような
主張がされることがあります。一方でそのとき、なにが問題でなにを解決するといったことに
着目することは少ないようです。

　上記の関係はまさにそれに対する回答でもあります。

　つまり (この記事において) Expression Problem を新たに定式化するのであれば

　　　　f1 : T → U, f2 : T → U, …, fm : T → U

　　　　x1 : T, x2 : T, …, xn : T

　とあったとき

　　　　g : T → U を実装するには x1, x2, …, xn の変更が必要

　　　　y : T を実装するには f1, f2, …, fm の変更が必要

　な状況を指します。

　たとえば、もし T が代数的データ型で定義されていたとすれば、 y : T を実装するには T の
変更が必要になり、これは f1, f2, …, fm の変更が必要になります。
また T がクラスで定義されていたとすれば、 g : T → U を実装するにはやはり T の変更が必要になり、
これは x1 : T, x2 : T, …, xn : T の変更が必要になります (この場合 x1 : T は継承関係を表すことになるかもしれませんし、
通常の型理論の記法にならうなら、匿名クラスと考えたほうがすんなり理解できるかもしれません)。

　ここで型クラスを定義したとすれば、値を追加する場合にはその instance 宣言を定義すればよいのであり、
また関数を追加する場合にも、やはりそれを型クラス制約で抽象化した関数を定義すればよいということです。

　また Expression Problem の文脈ではとくに再コンパイルに言及されることがあります。
実際再コンパイルが必要になるとビルドが長くなったりして困るなどありますが、
基本的には、変更しなければ再コンパイルは必要がないので、変更が必要ないということは再コンパイルする必要がない
ということを含む概念と言えます。

　これが『型クラスは Expression Problem を解決できる』という主張における問題とそれが解決された状況です。

　一方、型クラスの定義自体の変更には弱いことは明らかです。
型クラスの定義を変更すれば、当然すべての instance 宣言とすべての関数の定義を変更する必要があります。

@chapter
単相な言語でも Expression Problem に立ち向かうことはできる

　上記のように定式化された問題は、じつのところ単相な言語でも解決できます。
というのは、変更する必要がない型を定義すれば、上記のような問題は発生しないわけですから。
実際辞書渡し形式で実装すれば、型クラスとほとんど同じ抽象化が可能です。

　その一方で先述したように、型クラスを定義しても、それだけで即座に Expression Problem を解決できるということにはなりません。
たとえばひとつ関数を定義するたびに型クラスの定義を変更していたら、当然 Expression Problem と同等か、
それ以上の問題が発生します。

@chapter
Clean Architecture におけるふたつの主張 / 抽象と具象、依存の向き

　Clean Architecture というものがあります。
技術的な詳細を具象、概念的な仕様を抽象と捉えることも多いようですが、
ここではそういったアナロジーではなく変更可能性で考えます。つまり

　　　　A を変更したとき、 B をともに変更する必要があるならば、 A は B と同型かより抽象的であり、これを B ≲ A と書く。

　と定義します。これは

　　　　A ～ B ならば A を変更したとき、 B を変更する必要がある

　　　　A &gt; B ならば A を変更したとき、 B を変更する必要がある

　　　　A &lt; B ならば A を変更したとき、 B を変更する必要がない

　という性質を満たさなければなりません。
また（本題ではないので厳密に定義することはありませんが、通常の順序関係として） A &lt; B でないならば B ≲ A なので、 A, B はすくなくとも、

　　　　A を変更したとき B を変更する必要がないならば、 B を変更したとき A を変更する必要がある

　という依存関係にあります。また A ～ B の場合
『A を変更したときは B を変更する必要があり、かつ B を変更したときは A を変更する必要がある』
という関係になります。

　もし A, B のいずれを変更してもいずれも変更する必要がない場合、それはまったく無関係 (比較不能) ということになり、
これを含めると半順序関係になりますが、こういったものは今回は考えません。

　ここで『変更する必要がある』という言葉は厳密に定義することはありませんが、主に型チェックなどで検知できるものと、
（静的型つき言語であっても）意味的なものでチェックできないものがあります。

　これによって抽象と具象の定義が与えられました。つぎに内側と外側の話をします。

　Clean Architecture においては内側はより抽象的で、外側はより具象的でなければなりません。
また外側が内側に依存することはできますが、内側に外側が依存することはできません。

　ここでは有向グラフで考えてみます。まずなにかがなにかに依存する、という状況を x ▷ y と表し、 x は y に依存すると読んでみます。
つまり

　　　　x ▷ y であるとき、かつそのときにかぎり x は y に依存する。

　また内側と外側の定義もこれによって与えられます。つまり

　　　　x ▷ y であるとき、かつそのときにかぎり x は外側にあり、 y は内側にある。

　とします。

　実際に依存しているという状態は個別に与えられますが、たとえば識別子を参照しているとか、
なんらかの意味的な依存関係にある値 (たとえば名前を表す文字列) などです。

@chapter
型クラスを Clean Architecture として考える

　さて最初の定義に戻り

　　　　f : ∀a &lt;: T. a → U

　　　　S &lt;: T

　　　　x : S

　　　　f(x) : U

　の関係を考えてみます。

　まず T を T' に変更し、 T &lt;: T' である場合、 x を変更する必要は生じませんが、 f を変更する必要は生じます。
一方で T' &lt;: T である場合 f を変更する必要は生じませんが、 x を変更する必要は生じます。
そのいずれでもなく比較不能である場合、 f, x のいずれも変更する必要が生じます。
以上から T を変更することはできません。

　一方で S を S' 変更する場合、 S' &lt;: T であれば T を変更する必要は生じません。
現実にはそうでない場合もあるでしょうが、 S' &lt;: T の範囲での変更のみで済むように T が設計されていることを前提として、
そのような場合のことはここでは考えないこととします。

　x を x' に変更する場合、 x' : S であれば S を変更する必要は生じません。
そうでない場合でも、適当な S' &lt;: T を選んで x' : S' であれば T を変更する必要は生じません。

　f の変更というものは、 f の実装が必要としている最小の仮定を T &lt;: T1 としたとき f : T1 → U と具象化しても型検査が pass するとして、
これを f' : T2 → U と変更する場合ですが、もし T &lt;: T2 であれば T を変更する必要は生じません。
また T &lt;: T' の範囲での変更のみで済むように T が設計されていることを前提として、
やはりそうでない場合のことは考えないことにします。

　以上のことから

　　　　∀a &lt;: T. a → U ≲ T

　　　　S ≲ T

　　　　f ≲ ∀a &lt;: T. a → U

　　　　x ≲ S

　というような関係が成り立ち、また

　　　　∀a &lt;: T. a → U ▷ T

　　　　S ▷ T

　　　　f ▷ ∀a &lt;: T. a → U

　　　　x ▷ S

　も、識別子の関係を考えるに自然な依存関係です。

　これを有向グラフで考えると

　　　　{T, ∀a &lt;: T. a → U, S, f, x} ⊆ E

　　　　{∀a &lt;: T. a → U ▷ T, S ▷ T, f ▷ ∀a &lt;: T. a → U, x ▷ S} ⊆ V

　となります。

@chapter
インターフェースやコンストラクタ

　API のようなものを定義するとき、ある種の境界を設計し、インターフェースは守って
その境界以上に変更を波及させないという考え方があります。
インターフェース自体の変更を伴う場合は別ですが、通常は内部的な構造の変更を伴っても、
インターフェースは守ったうえで変更します。
これはまさに上記の T をそのインターフェースとするような場合の考え方です。

　またコンストラクタというものがあり、これもコンストラクタによって状態の正しさというものが検証され、
ひとたび値が構築されたならば、その後はどのような使い方をしても問題はないという
（ある種のライブラリアンの）考え方です。これもまた、上記のように考えることができます。
ただしコンストラクタの場合には、値の構成を好き勝手にされては困るので、（難しく考えるならば）存在型というものが必要になってきます。

　ちなみに有界存在型というものがあり、 ∃a &lt;: T. のような記号で表されます。
これは T のように扱うことができるけれども、 T そのものではない (ので T の値を勝手に構成したりはできない) というものです。

@chapter
抽象データ型、クラス、モジュール

　抽象データ型というものがあり、クラスやモジュールで定義されます。
オブジェクト指向言語ではクラスによってデータと操作は不可分なものとして表されるけれども、
関数型言語ではモジュールと型、関数は分離され、その組み合わせによって表されます。

　いずれにしても通常、上記のように公開するものと公開しないものは明確な境界をもつように設計されます。

（もちろんそうでないライブラリも現実にはあります。あまりよくないとは思いますが、
こういったライブラリでは境界の外側で『不正な状態の』値を構成することが可能などがあります。
こういった値は関数の呼び出し時にエラーになるなどがあります）

@chapter
どこで境界を切るべきか？ / トップダウンとボトムアップ / アプリケーション開発の難しさ

　アプリケーションを開発するとき、もっとも難しいと感じるのはこの境界の設計です。
とりわけ API よりも、内部的なソースコードにおける境界というものの設計は
非常に難しいと感じます。というのは、人間は常にアナロジーで考えてしまうからです。

　有向グラフで考えると思いのほか自明なのですが、分離すべきものは分離する、
分離すべきでないものは分離しないという単位に関する考え方が非常に難しい。

　たとえば A ～ B であるものは、 A を変更しても常に B を変更する必要があり、 B を変更しても常に B を変更する必要がある
（密結合している）ので分離しないほうがいいと思う。一方で A ≲ B であるものは分離したい。

　一方で A ≲ B のように分離すると、どんどん人間の直観から離れた抽象的なものになってしまい、
内側ほど過剰に抽象的でいったいなにが処理されているのかがわからないものに近づきます。
外側であればあるほど人間の直観に近づき、内側であればあるほど機会の言葉に近づくのです。

　トップダウンな開発は A ≲ B ≲ C ≲ … とあったとき A から始め、
ボトムアップな開発は … ≲ X ≲ Y ≲ Z とあったとき Z から始めます。
ライブラリの開発は通常ボトムアップに開発し、これはそこそこうまくいく。
ライブラリの開発がやりやすいのは、この Z の部分がいろいろな事情で最初からわかっているからだと思います。
たとえば

　　　　言語処理系などで、中間言語やアセンブリが最初から頭のなかにある

　　　　RFC とかに最終的な処理結果が掲載されている

　　　　プログラミングを何度もしたことで、機械がいったいどう処理しているかが透けて見えるようになっている

　といった状況です。

　ここで『ライブラリ的な』考え方で開発を始めると、
機械の事情がまだわからないときにいきなりボトムアップに開発を始めてしまい、
うまくいきにくいのだと思います。

　また時流としてトップダウンよりもボトムアップな開発が流行（？）しているのもかかわっている気がします。
つまりもっとも内側に人間のアナロジーで型を定義してしまい、ボトムアップにアプリケーションを開発すると、
かなりの疎グラフですべての辺を手動で書くような開発になってしまいます。

　これは一般的なことですが、ライブラリであろうと API のクライアントライブラリであろうと、
人間の直観に即した型が定義されるのはもっとも外側の境界部分なわけです。
ライブラリでも、コンストラクタで valid な値を生成しているので、
より内側ではそれを前提として unsafe な処理をしていることは多い。
たとえばデータベースに保存するときには、どんな型だろうと最終的にはシリアライズしてしまうわけで、
もっとも内側では（より外側で検査していることを前提として）やや unsafe というか、そういう処理は許容されます。

@chapter
DI と疎結合な設計に関すること

　疎結合だとか密結合だとかいう言葉を使うとき、どうしてもこれは疎結合だよね、とか
これは密結合だよね、みたいなふわふわした会話になりがちで、じゃあどうして疎結合なのかとか、
そういうことはいまいちわかった気になりません。疎結合に書く、とはどういうことでしょうか。

　わたしなりの、すくなくともこの記事における回答は『一方を変更しても、他方を変更する必要がない性質』です。

　また DI に関する思いもあります。これもやはり ∀ による抽象化の一形態のような気がします。
実際 trait や型クラスで DI をすることはできるわけです。

@chapter
TDD に関する思いとテスト可能な設計

　TDD にはいろいろな思いがあります。

　最初に TDD に触れたとき、わたしはまだテストを書く必要性も、いったいなにを書けばいいのかもわかりませんでした。
これに関してはいろいろな考えがありますが、基本的にはテスト可能な設計という考え方が先だということです。

　テスト可能な設計とはなんぞや、というのも、やはり難しい。
ひとによっていろいろな意見があると思いますし、そのどれも、ある種の観点では正しいのだと思います。

　ただ基本的には、テスト対象によってテストの方法は異なります。
そしてテスト対象が時代によって移り変わる以上、どういった方法が正しいといったものはない気がします。
むかしは必要だったものも、現代では必要ないなどもありうると思います。

　ではすべてが時代によって変わるもので、変化しないものなどないのかというとそうでもないと思う。
今回述べたものは、テスト可能な設計の中心的な理念というか、基本原則をわたしなりに言葉にしたものです。
基本的には、疎結合な設計とテスト可能な設計はおおよそ等しい気がします。

　つまり TDD の基本は機能を疎結合な unit に分解して、その unit の test を書く、
ということです。ここで unit 同士の組み合わせでバグが発生しないみたいなのは大事で、
でなければ、 unit test がなにも意味をなさないほど網羅性がなくなってしまうからです。
そしてこういったものは通常は暗黙のうちに密結合したなにかが由来のバグだったりします。
ただし究極的には、こういった設計ができるとテストしなくてもバグが発生しなくなったりもしてしまいます。

　ではどうやって疎結合にするか、などは具体的にはいろいろな方法がある気がします。
そういった個別の方法は変わりうると思いますが、思うに、その基本原則というものは ∀ や ∃ で
おおよそ説明ができて、そういう考え方自体はほとんど変わらない気がします。

@section
不安を感じ、それをテストにしよう

　またもうひとつの大事な観点として、ありとあらゆるパターンを頭のなかであらかじめ想像できる必要があります。
つまり『こういう場合はどうなる？』とか『ああいう場合はどうなる？』といった不安を感じる能力みたいなのが
大事というか、漠然としてしまいますが、自分の書いたコードが（たとえ型があっていたり既存のテストが通っているとしても）動作する
という確信を持たず、常に不安を感じる能力みたいなものです。これを感じることができないと、
まずテストを書くことができません（なにを書いていいかがわからない）。

　こういった不安を感じる能力みたいなのが、正直 TDD という観点ではいちばん大事な気がしますが、
わたしはこれをどういったかたちで説明すればいいのかはわかりません。
インスピレーションとか、センスとか直観とか、どうしてもそういう語彙を使わないといけなくなってしまう。
とにかくありとあらゆるパターンを想像して徹底的に詰めるみたいな、そういう考え方です。
正直考え方としていちばん近いのは詰将棋とか、ぷよぷよな気もします。

　このあたりは proptest みたいに、わりと直観に頼らずに技術的にできるものもあります。
もちろんこれでできることがすべてでもないので、やっぱり最終的には直観というか、センスの領域になってしまう気もします。

@section
リファクタリングに関する考え方

　リファクタリングとはなにか、というのも難しい話ですが、
すくなくとも TDD の文脈においては、究極的にはテスト可能な設計を目指して設計を
リファクタリングするというものな気がします。リファクタリングをする、
みたいなことを言うとき、なんらかの観点でよりよいコードベースを目指したいからそうするわけです。
それが TDD ではテスト可能な設計、だというわけです。

　先述したようにテスト可能な設計というのは疎結合な設計とほぼ等しい、
というのはわたしの経験則ですが、そう感じます。
疎結合な設計というものは通常はどの文脈でもよい設計とされますし、
リファクタリングの目標として悪くないと思います。

　一方で疎結合って、なに？　みたいな話をすると疎結合という言葉の定義を探り始めてしまう。
そこで TDD ではテスト可能な設計という、より定量的な回答を与えてくれるのだと思います。
すくなくともテストコードは『疎結合』という自然言語の単語よりも実際に動くコードではあるので、
テストコードがたくさん書かれていたらテスト可能な設計であるというのは自分のコードベースは疎結合だ、
と自然言語で主張するよりは説得力があります。

@chapter
自動テストに関するふたつの側面

　自動テストにはふたつの側面があり、それは

　　　　(1) 操作の自動化

　　　　(2) 判断の自動化

というものです。

　たとえば通常、手動テストというものは

　　　　(1) なにか操作をする

　　　　(2) その操作の結果得られた出力が、正しいかどうかを判断する

という過程で行われます。

　通常、自動テストは (1), (2) のいずれも含めた概念です。よって一般には
なにか自動的に操作をしたうえで、 bool を帰す関数として実装されます。

　一方で (2) を取り除いた自動テストというのもありうると思います。
つまり

　　　　(1) なにか操作をして、その出力結果を保存する

　　　　(2) その結果を人間が見て、それが正しいかどうかを判断する

などです。

　この場合 (2) は手動で行われるので半自動テストとか、セミオートテストみたいに言うとかっこいいかもしれません（ほんまか）。

　実際 UI のテストなどはたとえば画像を出力するだとか、動画を出力するだとかを仮にしたとして、
それを機械的に正しい出力かどうかを判断するのは難しいわけです。
非常にヒューリスティックな要素が多くなってしまいますし、
仮にそういったヒューリスティックな要素を適当に bool に mapping したとして、
いろいろなものが足りなくなってしまう気がします。
一方で (1) さえも手動でやるのが正しいとはあまり思えなかったりする。

　というか実際にやってみればわかる気がしますが、ちょっとした変更でも毎回テストプレイなどしていると
実際テストプレイが O(n!) のオーダーで負担になる感じがします。
ちなみにある瞬間におけるコードベースの組み合わせだけでなく、
時系列的な変化におけるテスト回数も開発とともに累積して総合的にはとんでもない時間がかかってしまいます。

@chapter
意図的に組み合わせ爆発を起こすことはできるのか

　どんなソフトウェアであっても、組み合わせでバグが生じる余地というのは常にあります。
そしてテストする必要があるものというのはたいていの場合、そういった組み合わせなのです。
もし機能がたったの n 個だとしても、理屈上、そのテストは 1! + 2! + … + n! 個必要になってしまうのです。

　これはソフトウェアとは複雑系だからだ、と言うことはできますが、
では人間には複雑系など手に負えないのかというとそうでもないと思う。

　テスト対象が組み合わせ爆発を起こすのであれば、あえて実装自体を組み合わせ爆発を起こすように
実装すればいいという、ただそれだけのことでもあると思います。
これは組み合わせで機能を表現できるので、要素を追加すればするほど機能が爆発的に増加し、
そしてそのすべてがバグらないという、おもしろいというかおかしな状態に突入します。

@chapter
変更可能性の妥当性

　また今回変更可能性という概念で内側と外側を定義しましたが、
ではなぜ変更可能性によってそう定義するのかと言えば、これにも一定の経験則というか根拠があります。
よく言われるように、バグは直近の変更箇所のどこかで生まれます。
変更しなければバグらないというのは、ある種の真理なのです。

　またコードを書かなければバグらない、という金言もあります。
しかしコードを書かずになにかを生みだすことはできません。
ライブラリを使うにしろそれを呼び出したり組み合わせるコードを書く必要はありますし、
第一、だれかがコードを書いてライブラリを生みだし、メンテナンスしています。

　0 行のコードでなにかを生みだすことができないのだとすれば、できるだけ変更をしない、
あるいは、できるだけ変更をせずになにかを生みだす方法を考えるしかありません。

　テスト可能な設計というものにある種の共通項として考えられる中心的な理念があるとすれば、
きっと ∀ による抽象化なのだと思います。

@chapter
おまけ / ∧ と ∨ および ∀ と ∃ に関すること

　　　　∀x. P(x)

　　　　∃x. P(x)

　というものはそれぞれ

　　　　P(x1) ∧ P(x2) ∧ …

　　　　P(x1) ∨ P(x2) ∨ …

　というふうに、述語 (predicate) を無限に並べたものと考えられます。

　そこで

　　　　∀a &lt;: T. a → U

　というものは P(a) := a → U と置くと

　　　　P(S1) ∧ P(S2) ∧ …

　つまり

　　　　(S1 → U) ∧ (S2 → U) ∧ …

　という性質をもつものと考えられます。
実際これはいわゆる交叉型というものであり、
ある種のオーバーロードにも似ています。

　さて

　　　　S1 ∨ S2 ∨ …

　という合併型を考えます。ここで ∨ の除去則 (パターンマッチ) は

　　　　S1 ∨ S2, (S1 → U), (S2 → U) ⊢ U

　という形式をしています (Haskell の either :: (a → c) → (b → c) → Either a b → c 関数)。

　そう考えれば

　　　　(S1 → U) ∧ (S2 → U) ∧ …

　　　　S1 ∨ S2 ∨ …

　から U が結論できるのは自然なことです。結局、

　　　　∀a &lt;: T. a → U

　という形式で表される関数というのは、無限の直和を処理するものと基本的には等しいわけです。

　ただし S1, S2, … の共通項としての性質を T というひとつの型で表さなければならないというのが難しいところなのだと思います。

　現代では直和型というものが流行（？）し、いろいろなものを区別しているようです。
一方でそういった直和型を区別せずに扱うことも、通常はできます
（これは理論的な話ではなく完全に実践的な話）。

　さらに言えば通常、直和というのはどこかで分岐が必要なデータ構造であり、
分岐というものはなかなかに複雑なものですから、基本的には分岐しないで扱えるほうが安全です。

@chapter
おまけ / 設計とはなにか / 設計は実装よりも難しい？

　そもそも設計という言葉自体があいまいというか、ひとによってイメージするものが違うと思います。
ただ思うのは、設計というのは基本的には全体像を整えたりその方法を選択する行為であって、
そのどの部分も設計ではない、ということです。

　たとえばどんなデータベースを使うだとか、そういったアーキテクチャはたしかにある種の設計ですが、
それだけが設計ではない。そういったアーキテクチャとデータベースを操作するソースコード、
そしてそれをテストする方法だとかは通常不可分で、
それらも含めて設計する必要があるという、ただそれだけのことだと思います。

　一方でソースコードこそ設計書であり、現代ではコンパイルやリンクによっていろいろな
ことが自動化されているというのも（あまのじゃくなところはありますが）微妙にわからない。
ソースコードは通常、設計に対して詳細すぎるのです。
さらに言えばソースコードには設計段階で考慮される why だとか not why といった情報が
（コメントに書かれている場合もありますが）抜け落ちてしまう。
ソースコードは『これがなんであるか』には答えてくれますが
『なぜこれなのか』には答えてくれないのです。

　そういうわけで基本的には、設計というものがある種の実装と離れて独立に存在するというよりは、
設計は単に実装をより俯瞰的に見たもの、以上の意味はない気がします。
たとえばどういったデータベースを使うかどうかといった選定は設計段階で行いますが、
具体的にそれをデプロイした場合、それは実装に属するものな気がします。
実際稼働中のデータベースは『これがなんであるか』には答えてくれますが
『なぜこれなのか』には答えてくれません。

　また設計のほうが実装より難しいというのも、いまいちよくわからない。
どちらかというと難しいのは実装で、設計の難しさは、頭のなかで実装する難しさだと考えています。
要するに、すくなくともこうすれば実装できるという確信がなければ設計できはしない。

　また設計というものは頭のなかで『なぜこれなのか』といったことを考えつつ行うわけですが、
これもやはり、実装中にも常に考えることでもあります。それをコメントに書き残すことはないかもしれませんが、
どんなコードの断片も、常にどうしてそうするのかを考えつつ行います。

　個人的には、設計ができるかどうかというのは考え方として非常にあいまいなものになってしまうので、
より定量的に、見積りができるかどうかで考えたほうがいい気がします。
つまり見積りができるということは実装の詳細や具体的な計画やスケジュールに関して、
すくなくとも頭のなかでは正確に描けているわけです。そしてそれが設計ができるということでもあると思う。

　わたしが設計よりも見積りを重視しているのは、それが計測可能だからです。
つまり見積りというのはあとから振り返ってうまくできたかどうかというのを客観的に判別できる。
他人もそうですが、なにより自分自身にうそをつかずに済むというか、
自分ができるとかできないという基準を、自分の認知に頼らずに時間で判断できるのは大事なことだと思います。

@chapter
むすびに / 単純 (simple) さと複雑 (complex) さ

　なにかが simple だとか、なにかが complex だとかいう話をするとき、
たびたびなにが simple でなにが complex というようなイメージが異なるのを感じることがあります。
もとよりこういった自然言語の単語に唯一絶対の定義を求めるというのは、
そういうことを求めるのもありかもしれませんが、わたしはあまり賛同できません。
自然言語処理界隈では『言語はひとの数だけある』というほどです。

　ただし自分なりにきちんとした定義を与えて考えることは有意義だと思います。
すくなくとも自分のなかではこういった定義なのだ、ということで、
思考をクリアにしたり一貫した考え方ができたりします。
またこういった考え方は作品制作にもかなり活きると思います。

　そこでわたしにとっての simple さと complex さとはなにかといえば、
それでもやはり分野によって異なると感じますが、
すくなくともプログラミングにおいては、
ある種の組み合わせにおける性質です。
つまり、 simple なものは組み合わせたり、分解することができる。
一方で complex なものは組み合わせることも、分解することもできない。
そういう状態を指して simple だとか complex だとか言います。
またこういう定義は、 simple だとか complex という英単語の語義からしてもそんなに不自然なものではないとも思います。

　一方で simple なものは簡単じゃない、だとか、そういう言葉もちょくちょく耳にします。
これはわたしとしては、もともと Clojure のコミュニティから受け継いだ Simple Made Easy の
理念かもしれませんが、あまり賛同できない。というよりも、
比較できないものを比較している感じで、意味のある言明に思えないという感じです。

　たしかに simple なものをつくることは簡単ではない。
一方で simple なものを使うのは、やっぱり難しくあってはならない気がします。
すくなくとも、 simple は簡単に組み合わせたり分解したりできるものであるべきで、
そしてそういう意味では、やっぱり simple なもののほうが結局は簡単だとは思います。

　一方でたとえそれが simple なものであっても、組み合わせ方というのはやっぱり難しいとも思う。
組み合わせたり分解すること自体は簡単にできても、それでより大きな作品を制作するというのは難しいことです。
もとがどんなに simple なものであっても、組み合わせ方次第では容易に complex なものになってしまう。
それが複雑系の難しさであり、またおもしろさでもあると思います。

　ここで複雑系という言葉を出しましたが、実際、複雑系に対する関心はここ数年の
わたしのなかでも大きなテーマでもあります。複雑系というのは、単なる還元主義的な
方法論では立ち向かえないものがある。そういったものにいかに立ち向かうというか、
そういった手法にとても大きな関心があるのです。

@chapter
付録 / いろいろな定義のまとめ

@section
機能とテスト

　　　　A, B, C, …

　　　　t(A), t(B), t(C), …

@section
『組み合わせても安全』な性質

　　　　t(A), t(B) が pass するならば t(A, B), t(B, A) も pass する

@section
変更可能性

　　　　A ≲ B …… B を変更したならば A も変更する必要がある

@section
依存関係

　　　　A ▷ B …… A は B に依存している

@section
依存関係の有向グラフ

　　　　A, B, C, … ∈ V

　　　　A ▷ B, C ▷ D, … ∈ E

@section
Clean Architecture

　　　　A ≲ B ⇔ A ▷ B ∈ E

　　　　A &gt; B ⇔ ¬(A ▷ B ∈ E)
